{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import Tensor\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "headlines = train_data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f\"Instruct: {task_description}\\nQuery: {query}\"\n",
    "\n",
    "\n",
    "# Each query must come with a one-sentence instruction that describes the task\n",
    "task = \"Given a Korean news headline, retrieve other news headlines that discuss similar topics or events.\"\n",
    "\n",
    "input_texts = [\n",
    "    get_detailed_instruct(task, headline)\n",
    "    for headline in headlines  # headlines는 뉴스 헤드라인 리스트\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large-instruct\")\n",
    "model = AutoModel.from_pretrained(\"intfloat/multilingual-e5-large-instruct\").to(\"cuda\")\n",
    "\n",
    "batch_size = 64  # 배치 크기 설정\n",
    "all_embeddings = []\n",
    "\n",
    "for i in range(0, len(input_texts), batch_size):\n",
    "    # 배치 단위로 토큰화\n",
    "    batch_input_texts = input_texts[i:i + batch_size]\n",
    "    batch_dict = tokenizer(\n",
    "        batch_input_texts,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 모델로부터 임베딩 생성 및 평균 풀링\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "        batch_embeddings = average_pool(\n",
    "            outputs.last_hidden_state, batch_dict[\"attention_mask\"]\n",
    "        )\n",
    "        batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "        all_embeddings.append(batch_embeddings.cpu())\n",
    "\n",
    "# 전체 임베딩 텐서로 결합\n",
    "embeddings = torch.cat(all_embeddings)\n",
    "\n",
    "scores = embeddings @ embeddings.T\n",
    "scores.fill_diagonal_(-1)  # query인 문장은 유사도 계산에서 제외\n",
    "train_data[\"embedding\"] = embeddings.cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가할 열 이름들\n",
    "new_columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "# 각 열에 대해 0으로 채운 값 추가\n",
    "for col in new_columns:\n",
    "    train_data[col] = 0\n",
    "\n",
    "# 결과 확인\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 문장 중 공통된 label을 뽑는 과정\n",
    "# 두 가지 접근법\n",
    "# 1. query와 관련된 상위 50개 문장의 label 중 가장 많은 클래스로 label을 수정하는 방식 (top-k_vote 열에 기록)\n",
    "# 2. 각 문장이 어떠한 label로 얼마나 많이 retrieve 되었는지를 세어서 가장 많이 사용된 label로 수정하는 방식 (max_0-6 열에 기록)\n",
    "\n",
    "for i in range(0, len(train_data)):\n",
    "    vote = []\n",
    "    top_scores, top_indices = scores[i].topk(50)\n",
    "    print(\n",
    "        f\"헤드라인 {i}와 유사한 상위 50개 헤드라인:\",\n",
    "        headlines[i],\n",
    "        train_data[\"target\"][i],\n",
    "    )\n",
    "    for score, idx in zip(top_scores, top_indices):\n",
    "        print(\n",
    "            f\"  - 헤드라인 {idx}: 유사도 {score.item()}\",\n",
    "            headlines[idx],\n",
    "            train_data[\"target\"][idx.item()],\n",
    "        )\n",
    "        vote.append(train_data[\"target\"][idx.item()])\n",
    "    count = collections.Counter(vote)\n",
    "    train_data.loc[i, \"top-k_vote\"] = max(count, key=count.get)\n",
    "    print(count)\n",
    "    for score, idx in zip(top_scores, top_indices):\n",
    "        train_data.loc[idx.item(), str(max(count, key=count.get))] += 1\n",
    "train_data[\"max_0-6\"] = train_data.loc[:, \"0\":\"6\"].idxmax(axis=1)\n",
    "train_data[\"top-k_vote\"] = train_data[\"top-k_vote\"].astype(int)\n",
    "train_data[\"max_0-6\"] = train_data[\"max_0-6\"].astype(int)\n",
    "train_data[\"same\"] = train_data[\"top-k_vote\"] == train_data[\"max_0-6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# threshold 설정\n",
    "threshold = np.percentile(scores, 80)\n",
    "# 임계값보다 낮은 유사도는 0으로 설정\n",
    "scores[scores < threshold] = 0\n",
    "\n",
    "# 스펙트럴 클러스터링 수행\n",
    "n_clusters = 7  # 원하는 군집 수\n",
    "spectral_cluster = SpectralClustering(\n",
    "    n_clusters=n_clusters, affinity=\"precomputed\", random_state=42\n",
    ")\n",
    "clusters = spectral_cluster.fit_predict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"SpectralClustering\"] = clusters\n",
    "\n",
    "# 매핑 딕셔너리 생성\n",
    "# SpectralClustering하여 얻은 클래스 번호가 train data의 클래스 번호가 다르기 때문에 시각화 및 비교를 하기 위해 매핑\n",
    "mapping = {0: 5, 1: 2, 2: 6, 3: 1, 4: 3, 5: 4, 6: 0}  # 원하는 대로 값 매핑\n",
    "train_data[\"SpectralClustering_mapping\"] = train_data[\"SpectralClustering\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 데이터를 배열로 변환\n",
    "embeddings = np.array(train_data[\"embedding\"].tolist())\n",
    "\n",
    "# t-SNE를 통해 2차원으로 차원 축소\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# 차원 축소된 데이터를 데이터프레임에 추가\n",
    "train_data[\"tsne_2d_x\"] = embeddings_2d[:, 0]\n",
    "train_data[\"tsne_2d_y\"] = embeddings_2d[:, 1]\n",
    "\n",
    "\n",
    "# 서브플롯 생성\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "# 첫 번째 시각화 - train data의 target\n",
    "sns.scatterplot(\n",
    "    x=\"tsne_2d_x\",\n",
    "    y=\"tsne_2d_y\",\n",
    "    hue=\"target\",  # target 열을 기준으로 색상 지정\n",
    "    palette=sns.color_palette(\"hsv\", len(train_data[\"target\"].unique())),\n",
    "    data=train_data,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7,\n",
    "    ax=axes[0, 0],\n",
    ")\n",
    "axes[0, 0].set_title(\"t-SNE Visualization by Target Label\")\n",
    "axes[0, 0].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[0, 0].set_ylabel(\"t-SNE Dimension 2\")\n",
    "axes[0, 0].legend(loc=\"best\")\n",
    "\n",
    "# 두 번째 시각화 - Spectral Clustering\n",
    "sns.scatterplot(\n",
    "    x=\"tsne_2d_x\",\n",
    "    y=\"tsne_2d_y\",\n",
    "    hue=\"SpectralClustering_mapping\",  # SpectralClustering_mapping 열을 기준으로 색상 지정\n",
    "    palette=sns.color_palette(\n",
    "        \"hsv\", len(train_data[\"SpectralClustering_mapping\"].unique())\n",
    "    ),\n",
    "    data=train_data,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7,\n",
    "    ax=axes[0, 1],\n",
    ")\n",
    "axes[0, 1].set_title(\"t-SNE Visualization of by Spectral Clustering\")\n",
    "axes[0, 1].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[0, 1].set_ylabel(\"t-SNE Dimension 2\")\n",
    "axes[0, 1].legend(loc=\"best\")\n",
    "\n",
    "# 세 번째 시각화 - query와 관련된 상위 50개 문장의 label 중 가장 많은 클래스로 label을 수정하는 방식\n",
    "sns.scatterplot(\n",
    "    x=\"tsne_2d_x\",\n",
    "    y=\"tsne_2d_y\",\n",
    "    hue=\"top-k_vote\",  # top-k_vote 열을 기준으로 색상 지정\n",
    "    palette=sns.color_palette(\"hsv\", len(train_data[\"top-k_vote\"].unique())),\n",
    "    data=train_data,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7,\n",
    "    ax=axes[1, 0],\n",
    ")\n",
    "axes[1, 0].set_title(\"t-SNE Visualization by Majority Label in Top-50 Retrievals\")\n",
    "axes[1, 0].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[1, 0].set_ylabel(\"t-SNE Dimension 2\")\n",
    "axes[1, 0].legend(loc=\"best\")\n",
    "\n",
    "# 네 번째 시각화 - 각 문장이 어떠한 label로 얼마나 많이 retrieve 되었는지를 세어서 가장 많이 사용된 label로 수정하는 방식\n",
    "sns.scatterplot(\n",
    "    x=\"tsne_2d_x\",\n",
    "    y=\"tsne_2d_y\",\n",
    "    hue=\"max_0-6\",  # max_0-6 열을 기준으로 색상 지정\n",
    "    palette=sns.color_palette(\"hsv\", len(train_data[\"max_0-6\"].unique())),\n",
    "    data=train_data,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7,\n",
    "    ax=axes[1, 1],\n",
    ")\n",
    "axes[1, 1].set_title(\n",
    "    \"t-SNE Visualization by Aggregated Majority Voting Across Top-50 Retrievals\"\n",
    ")\n",
    "axes[1, 1].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[1, 1].set_ylabel(\"t-SNE Dimension 2\")\n",
    "axes[1, 1].legend(loc=\"best\")\n",
    "\n",
    "# 전체 레이아웃 조정 및 출력\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data_relabeled.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
